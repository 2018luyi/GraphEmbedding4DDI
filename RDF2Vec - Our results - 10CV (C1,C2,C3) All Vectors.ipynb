{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of drug-drug interaction using RDF2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_curve, auc,average_precision_score\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import random\n",
    "import numbers\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read RDF2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNegativeSize(all_combs, positive_pairs, n_propotion):\n",
    "    x= len(all_combs) - len(positive_pairs) \n",
    "    if x < len(positive_pairs)*n_propotion:\n",
    "         negative_size=x\n",
    "    else:\n",
    "        negative_size=len(positive_pairs)*n_propotion\n",
    "        \n",
    "    return negative_size\n",
    "\n",
    "def getDataFrame(pairs, cls):\n",
    "    pairs = np.array(pairs)\n",
    "    if cls == 1:\n",
    "        classes = np.ones(len(pairs))\n",
    "    else:\n",
    "        classes = np.zeros(len(pairs))\n",
    "    #classes = numpy.full((len(pairs)), cls)\n",
    "    data = list(zip(pairs[:,0],pairs[:,1],classes))\n",
    "    #print (data)\n",
    "    df = pd.DataFrame(data,columns=['Drug1','Drug2','Class'])\n",
    "    return df\n",
    "\n",
    "def select_negative_samples(train_drugs, test_drugs, train_pairs, test_pairs_C1, test_pairs_C2, test_pairs_C3, n_propotion):\n",
    "    # negative samples for training\n",
    "    all_combs = set(itertools.combinations(sorted(train_drugs),2))\n",
    "    #print(\"train all pairs\",len(all_combs))\n",
    "    #print(\"train pairs\", train_pairs)\n",
    "    # check whether there is enough pairs to be added as negatives\n",
    "    \n",
    "    negative_size=getNegativeSize(all_combs, train_pairs, n_propotion)\n",
    "    unknowPairs = all_combs.difference(train_pairs).difference(test_pairs_C1)\n",
    "    train_negatives =random.sample(unknowPairs, negative_size)\n",
    "    #print(\"train negatives\", train_negatives)\n",
    "    \n",
    "    negative_size=getNegativeSize(unknowPairs, test_pairs_C1, n_propotion)\n",
    "    test_negatives_C1 =random.sample(unknowPairs.difference(train_negatives), negative_size)\n",
    "     \n",
    "    all_combs = set([ tuple(sorted([drug1,drug2]))  for drug1 in train_drugs for drug2 in test_drugs])\n",
    "    #print(\"C2 all pairs\",len(all_combs))    \n",
    "    negative_size = getNegativeSize(all_combs, test_pairs_C2, n_propotion) \n",
    "    test_negatives_C2 =random.sample(all_combs.difference(test_pairs_C2), negative_size)\n",
    "    #print(\"test_negatives_C2 \", test_negatives_C2)\n",
    "    \n",
    "    all_combs = set(itertools.combinations(sorted(test_drugs),2))\n",
    "    #print(\"C3 all pairs\",len(all_combs))    \n",
    "    negative_size = getNegativeSize(all_combs, test_pairs_C3, n_propotion) \n",
    "    test_negatives_C3 =random.sample(all_combs.difference(test_pairs_C3), negative_size)\n",
    "    #print(\"test_negatives_C3 \", test_negatives_C3)\n",
    "    \n",
    "    return train_negatives,test_negatives_C1, test_negatives_C2, test_negatives_C3\n",
    "\n",
    "def drugwise_k_fold_cross(all_drugs, all_pairs, n_fold ):\n",
    "    n_subsets = int(len(all_drugs)/n_fold)\n",
    "    subsets = dict()\n",
    "    remain = all_drugs\n",
    "    for i in range(0,n_fold-1):\n",
    "        subsets[i] = random.sample(remain, n_subsets)\n",
    "        remain =remain.difference(subsets[i])\n",
    "    subsets[n_fold-1]= list(remain)\n",
    "    \n",
    "    for i in reversed(range(0, n_fold)):\n",
    "        test_drugs = subsets[i]\n",
    "        train_drugs = []\n",
    "        for j in range(0, n_fold):\n",
    "            if i != j:\n",
    "                train_drugs.extend(subsets[j])\n",
    "    \n",
    "        #print(\"train drugs\",train_drugs)\n",
    "        #print(\"test drugs\",test_drugs)\n",
    "        train_pairs = []\n",
    "        # training pairs\n",
    "        for pair in all_pairs:\n",
    "            drug1 = pair[0]\n",
    "            drug2 = pair[1]\n",
    "            if drug1 in train_drugs and drug2 in train_drugs:\n",
    "                train_pairs.append(pair)\n",
    "\n",
    "      \n",
    "         # test pairs\n",
    "        test_pairs_C1 =[]\n",
    "        n = len(train_pairs)//n_fold\n",
    "       \n",
    "        for i in range(n):\n",
    "            pair = random.choice(train_pairs)\n",
    "            train_pairs.remove(pair)\n",
    "            test_pairs_C1.append(pair)\n",
    "        \n",
    "        test_pairs_C2 =[]\n",
    "        test_pairs_C3 =[]\n",
    "        for pair in all_pairs:\n",
    "            drug1 = pair[0]\n",
    "            drug2 = pair[1]\n",
    "            if drug1 in test_drugs and drug2 in test_drugs:\n",
    "                test_pairs_C3.append(pair)\n",
    "            elif drug1 in test_drugs or drug2 in test_drugs:\n",
    "                test_pairs_C2.append(pair)\n",
    "\n",
    "        yield train_drugs, test_drugs,train_pairs, test_pairs_C1, test_pairs_C2, test_pairs_C3        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multimetric_score(estimator, X_test, y_test, scorers):\n",
    "    \"\"\"Return a dict of score for multimetric scoring\"\"\"\n",
    "    scores = {}\n",
    "    for name, scorer in scorers.items():\n",
    "        if y_test is None:\n",
    "            score = scorer(estimator, X_test)\n",
    "        else:\n",
    "            score = scorer(estimator, X_test, y_test)\n",
    "\n",
    "        if hasattr(score, 'item'):\n",
    "            try:\n",
    "                # e.g. unwrap memmapped scalars\n",
    "                score = score.item()\n",
    "            except ValueError:\n",
    "                # non-scalar?\n",
    "                pass\n",
    "        scores[name] = score\n",
    "\n",
    "        if not isinstance(score, numbers.Number):\n",
    "            raise ValueError(\"scoring must return a number, got %s (%s) \"\n",
    "                             \"instead. (scorer=%s)\"\n",
    "                             % (str(score), type(score), name))\n",
    "    return scores\n",
    "\n",
    "def cross_validate(clf, all_drugs, all_pairs, embedding_df, n_fold, f, n_propotion=1):\n",
    "\n",
    "    drug_k_fold = drugwise_k_fold_cross(all_drugs, all_pairs, n_fold)\n",
    "    c1_results = pd.DataFrame()\n",
    "    c2_results = pd.DataFrame()\n",
    "    c3_results = pd.DataFrame()\n",
    "    \n",
    "    for i,(fold_data) in enumerate(drug_k_fold):\n",
    "        #print (fold_data)\n",
    "        train_drugs, test_drugs, train_positives, test_positives_C1, test_positives_C2, test_positives_C3 = fold_data\n",
    "        print (\"train drugs\",len(train_drugs),\"test drugs\",len(test_drugs), file=f)\n",
    "        train_negatives,test_negatives_C1, test_negatives_C2, test_negatives_C3 = select_negative_samples(train_drugs, test_drugs, train_positives, test_positives_C1, test_positives_C2, test_positives_C3, n_propotion=1)\n",
    "        train =  pd.concat([getDataFrame(train_positives, 1),  getDataFrame(train_negatives, 0)],ignore_index=True) \n",
    "       \n",
    "        test_C1 =  pd.concat([getDataFrame(test_positives_C1, 1),  getDataFrame(test_negatives_C1, 0)],ignore_index=True)\n",
    "        test_C2 =  pd.concat([getDataFrame(test_positives_C2, 1),  getDataFrame(test_negatives_C2, 0)],ignore_index=True)   \n",
    "        test_C3 =  pd.concat([getDataFrame(test_positives_C3, 1),  getDataFrame(test_negatives_C3, 0)],ignore_index=True) \n",
    "        train = train.merge(embedding_df, left_on='Drug1', right_on='Drug').merge(embedding_df, left_on='Drug2', right_on='Drug')\n",
    "        test_C1 = test_C1.merge(embedding_df, left_on='Drug1', right_on='Drug').merge(embedding_df, left_on='Drug2', right_on='Drug')\n",
    "        test_C2 = test_C2.merge(embedding_df, left_on='Drug1', right_on='Drug').merge(embedding_df, left_on='Drug2', right_on='Drug')\n",
    "        test_C3 = test_C3.merge(embedding_df, left_on='Drug1', right_on='Drug').merge(embedding_df, left_on='Drug2', right_on='Drug')\n",
    "\n",
    "        \n",
    "        #train = train.merge(rdf2vec_df1, on=['Drug1']).merge(rdf2vec_df2, on=['Drug2'])\n",
    "        #test_C1 = test_C1.merge(rdf2vec_df1, on=['Drug1']).merge(rdf2vec_df2, on=['Drug2'])\n",
    "        #test_C2 = test_C2.merge(rdf2vec_df1, on=['Drug1']).merge(rdf2vec_df2, on=['Drug2'])\n",
    "        #test_C3 = test_C3.merge(rdf2vec_df1, on=['Drug1']).merge(rdf2vec_df2, on=['Drug2'])\n",
    "        #print (train.columns)\n",
    "        features = train.columns.difference(['Drug1','Drug2' ,'Class', 'Drug_x', 'Drug_y'])\n",
    "        X_train = train[features].values\n",
    "        y_train = train['Class'].values\n",
    "\n",
    "        X_test_C1 = test_C1[features].values\n",
    "        y_test_C1 = test_C1['Class'].values\n",
    "                             \n",
    "        X_test_C2 =  test_C2[features].values\n",
    "        y_test_C2 = test_C2['Class'].values\n",
    "\n",
    "        X_test_C3 =  test_C3[features].values\n",
    "        y_test_C3 = test_C3['Class'].values\n",
    "\n",
    "        print(\"train positive set:\", len(y_train[y_train==1]), \" negative set:\", len(y_train[y_train==0]), file=f)\n",
    "        print(\"C1 test positive set:\",len(y_test_C1[y_test_C1==1]),\" negative set:\",len(y_test_C1[y_test_C1==0]), file=f)\n",
    "        print(\"C2 test positive set:\",len(y_test_C2[y_test_C2==1]),\" negative set:\",len(y_test_C2[y_test_C2==0]), file=f)\n",
    "        print(\"C3 test positive set:\",len(y_test_C3[y_test_C3==1]),\" negative set:\",len(y_test_C3[y_test_C3==0]), file=f)\n",
    "        #probas_ = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        scoring = ['precision', 'recall', 'accuracy', 'roc_auc', 'f1', 'average_precision']\n",
    "        scorers, multimetric = metrics.scorer._check_multimetric_scoring(clf, scoring=scoring)\n",
    "        #print(scorers)\n",
    "        scores = multimetric_score(clf, X_test_C1, y_test_C1, scorers)\n",
    "        print (\"C1\",scores, file=f)\n",
    "        c1_results = c1_results.append(scores, ignore_index=True)                     \n",
    "                             \n",
    "        scores = multimetric_score(clf, X_test_C2, y_test_C2, scorers)\n",
    "        print (\"C2\",scores, file=f)\n",
    "        c2_results = c2_results.append(scores, ignore_index=True)\n",
    "        \n",
    "        scores = multimetric_score(clf, X_test_C3, y_test_C3, scorers)\n",
    "        print (\"C3\",scores, file=f)\n",
    "        c3_results = c3_results.append(scores, ignore_index=True)\n",
    "        \n",
    "        print(\"-----------------------------------------------------------------------------\", file=f)\n",
    "        print(\"-----------------------------------------------------------------------------\", file=f)\n",
    "\n",
    "        del X_train, y_train, X_test_C1, y_test_C1, X_test_C2, y_test_C2, X_test_C3, y_test_C3\n",
    "        del train_drugs, test_drugs, train_positives, test_positives_C1,test_positives_C2, test_positives_C3\n",
    "        del train_negatives,test_negatives_C1,test_negatives_C2, test_negatives_C3\n",
    "        gc.collect()\n",
    "        \n",
    "    return c1_results,c2_results, c3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crossvalidation(model, commonDrugs, all_positives, embedding_df, n_fold, n_run, n_propotion=1):\n",
    "    c1_results_runs = pd.DataFrame()\n",
    "    c2_results_runs = pd.DataFrame()\n",
    "    c3_results_runs = pd.DataFrame()\n",
    "    logfile =open('log.txt', 'w')\n",
    "    for i in range(n_run):\n",
    "        c1_results, c2_results, c3_results = cross_validate(model, commonDrugs, all_positives, embedding_df, n_fold, logfile, n_propotion)\n",
    "        c1_results_runs = c1_results_runs.append(c1_results.mean(), ignore_index=True)\n",
    "        c2_results_runs = c2_results_runs.append(c2_results.mean(), ignore_index=True)\n",
    "        c3_results_runs = c3_results_runs.append(c3_results.mean(), ignore_index=True)\n",
    "    \n",
    "    return c1_results_runs, c2_results_runs, c3_results_runs\n",
    "\n",
    "\n",
    "def main(drugfeat, ddifile):\n",
    "\n",
    "   \n",
    "    print (\"Processing file :\",drugfeat)\n",
    "    # ### Reading the RDF2Vec features\n",
    "    \n",
    "    embedding_df = pd.read_csv(drugfeat, delimiter='\\t')\n",
    "\n",
    "    #print('Size of the drugs that has RDF2Vec features: %d' % len(embedding_df))\n",
    "\n",
    "\n",
    "    # ### Reading Drugbak v5.0 dataset\n",
    "    drugbank_ddi = pd.read_csv(ddifile, delimiter='\\t')\n",
    "\n",
    "\n",
    "    print(\"Dataset size: %d\" % len(drugbank_ddi)) # it should be 13892 (6946*2) but it doesn't affect the comparison procedure\n",
    "\n",
    "    drugsInDrugbankDDI = set(drugbank_ddi['Drug1'].unique()).union(drugbank_ddi['Drug2'].unique())\n",
    "    commonDrugs = drugsInDrugbankDDI.intersection(embedding_df.Drug.unique()).intersection(embedding_df.Drug.unique())\n",
    "\n",
    "    print(\"Size of the drugs that appear in both DrugBank DDI dataset and drug2vec dataset: \", len(commonDrugs))\n",
    "\n",
    "    import itertools\n",
    "    pairs = []\n",
    "    classes = []\n",
    "\n",
    "    ddiKnown = set([tuple(x) for x in  drugbank_ddi[['Drug1','Drug2']].values])\n",
    "            \n",
    "    for comb in itertools.combinations(sorted(commonDrugs),2):\n",
    "        dr1=comb[0]\n",
    "        dr2=comb[1]\n",
    "        if (dr1,dr2)  in ddiKnown or  (dr2,dr1)  in ddiKnown:\n",
    "            pairs.append((dr1,dr2))\n",
    "\n",
    "    all_positives = set(pairs)\n",
    "    n_seed = 112\n",
    "    n_fold = 10\n",
    "    n_run = 10\n",
    "    n_propotion=1\n",
    "\n",
    "    # ### Naive Bayes\n",
    "    # There is no hyper-parameter to tune. \n",
    "    nb_model = GaussianNB()\n",
    "    print (\"Naive Bayes\")\n",
    "    #nb_mean_fpr, nb_mean_tpr, nb_precision, nb_recall = crossvalidation(nb_model, X, y, nsplits=10) train_df_emd\n",
    "    nb_scores_df = crossvalidation(nb_model, commonDrugs, all_positives, embedding_df, n_fold, n_run, n_propotion)\n",
    "\n",
    "    # ### Logistic Regression\n",
    "    # **Training with best parameters:**\n",
    "    # Value for C parameter was selected as 0.01\n",
    "\n",
    "    logistic_model = LogisticRegression(C=0.01)\n",
    "\n",
    "    print (\"Logistic Regression\")\n",
    "    lr_scores_df = crossvalidation(logistic_model, commonDrugs, all_positives, embedding_df, n_fold, n_run, n_propotion)\n",
    "\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "\n",
    "    print (\"Random Forest\")\n",
    "    #rf_results_pred = None\n",
    "    rf_scores_df = crossvalidation(rf_model, commonDrugs, all_positives, embedding_df, n_fold, n_run, n_propotion)\n",
    "\n",
    "     \n",
    "    return nb_scores_df, lr_scores_df, rf_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with each embedding features and output the results of classifiers (NB, LR, RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### DRUGBANK DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "foldername = 'vectors/DRUGBANK/' \n",
    "ddi_file ='data/input/ddi_v5.txt'\n",
    "outfolder='Results/DRUGBANK/'\n",
    "\n",
    "for fn in os.listdir(foldername):\n",
    "    emdfile = os.path.join(foldername, fn)\n",
    "    nb_results_pred, lr_results_pred, rf_results_pred = main(emdfile, ddi_file)\n",
    "\n",
    "    nb_results_pred.to_csv(outfolder+fn[:-4]+'_nb_results_pred.csv')\n",
    "    lr_results_pred.to_csv(outfolder+fn[:-4]+'_lr_results_pred.csv')\n",
    "    rf_results_pred.to_csv(outfolder+fn[:-4]+'_rf_results_pred.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### INTEGRATED (DRUGBANK, KEGG, PHARMGKB) DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file : vectors/DRUGBANK/Drug2Vec_sg_200_5_5_15_2_500_uniform.txt\n",
      "Dataset size: 577712\n",
      "Size of the drugs that appear in both DrugBank DDI dataset and drug2vec dataset:  2124\n",
      "Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "foldername =  'vectors/DB_KEGG_PGK/'\n",
    "fn = 'Drug2Vec_sg_200_5_5_15_2_500_uniform.txt'\n",
    "ddi_file ='data/input/ddi_v5.txt'\n",
    "outfolder='Results/DB_KEGG_PGK/' \n",
    "\n",
    "emdfile = os.path.join(foldername, fn)\n",
    "nb_results_pred, lr_results_pred, rf_results_pred = main(emdfile, ddi_file)\n",
    "nb_results_pred[0].to_csv(outfolder+fn[:-4]+'_nb_results_C1.csv')\n",
    "nb_results_pred[1].to_csv(outfolder+fn[:-4]+'_nb_results_C2.csv')\n",
    "nb_results_pred[2].to_csv(outfolder+fn[:-4]+'_nb_results_C3.csv')\n",
    "lr_results_pred[0].to_csv(outfolder+fn[:-4]+'_lr_results_C1.csv')\n",
    "lr_results_pred[1].to_csv(outfolder+fn[:-4]+'_lr_results_C2.csv')\n",
    "lr_results_pred[2].to_csv(outfolder+fn[:-4]+'_lr_results_C3.csv')\n",
    "rf_results_pred[0].to_csv(outfolder+fn[:-4]+'_rf_results_C1.csv')\n",
    "rf_results_pred[1].to_csv(outfolder+fn[:-4]+'_rf_results_C2.csv')\n",
    "rf_results_pred[2].to_csv(outfolder+fn[:-4]+'_rf_results_C3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#foldername = '../rdfvec/vectors/DB_KEGG_PGK/' \n",
    "foldername =  'vectors/DB_KEGG_PGK/'\n",
    "ddi_file ='data/input/ddi_v5.txt'\n",
    "outfolder='Results/DB_KEGG_PGK/'\n",
    "scores_runs = pd.DataFrame()\n",
    "\n",
    "for fn in os.listdir(foldername):\n",
    "    emdfile = os.path.join(foldername, fn)\n",
    "    if 'trans' not in fn: continue\n",
    "    nb_results_pred, lr_results_pred, rf_results_pred = main(emdfile, ddi_file)\n",
    "    nb_results_pred[0].to_csv(outfolder+fn[:-4]+'_nb_results_C1.csv')\n",
    "    nb_results_pred[1].to_csv(outfolder+fn[:-4]+'_nb_results_C2.csv')\n",
    "    nb_results_pred[2].to_csv(outfolder+fn[:-4]+'_nb_results_C3.csv')\n",
    "    lr_results_pred[0].to_csv(outfolder+fn[:-4]+'_lr_results_C1.csv')\n",
    "    lr_results_pred[1].to_csv(outfolder+fn[:-4]+'_lr_results_C2.csv')\n",
    "    lr_results_pred[2].to_csv(outfolder+fn[:-4]+'_lr_results_C3.csv')\n",
    "    rf_results_pred[0].to_csv(outfolder+fn[:-4]+'_rf_results_C1.csv')\n",
    "    rf_results_pred[1].to_csv(outfolder+fn[:-4]+'_rf_results_C2.csv')\n",
    "    rf_results_pred[2].to_csv(outfolder+fn[:-4]+'_rf_results_C3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
